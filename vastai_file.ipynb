{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0aae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "url = \"https://drive.google.com/u/0/uc?id=1Oqt3Kpl8W0OR715ac_evMv8GQHvnXWO5&export=download\"\n",
    "output = \"cropped_video.zip\"\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd908538",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pytorch-lightning -q\n",
    "!pip install neptune-client -q\n",
    "!pip install iopath -q\n",
    "!pip !install av -q\n",
    "!git clone https://github.com/talhaanwarch/pytorchvideo.git\n",
    "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113 --upgrade\n",
    "!pip install torchtext==0.12.0 --upgrade\n",
    "!pip install fvcore -q\n",
    "!pip install wandb -q\n",
    "!pip install av -q\n",
    "# !pip install gdown\n",
    "!pip install matplotlib\n",
    "!pip install -U albumentations\n",
    "!pip install openpyxl pandas\n",
    "# !pip install pytorchvideo\n",
    "# !pip uninstall pytorchvideo --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42188e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau,CosineAnnealingWarmRestarts,OneCycleLR,CosineAnnealingLR\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset,ConcatDataset\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import KFold,GroupShuffleSplit,GroupKFold,LeaveOneGroupOut\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.utils import shuffle\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594370c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./temp\n",
    "!sudo apt-get install unzip -y\n",
    "!unzip -d ./temp/ cropped.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('new_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vital='Pulse'\n",
    "df=df[['path',vital]]\n",
    "df.columns=['path','value']\n",
    "df.path='temp/'+df['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexpath = df[ (df['value'] < 60)].index\n",
    "# & (df['value'] < 89) ].index\n",
    "df.drop(indexpath , inplace=True)\n",
    "# df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ee3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexpath=df[(df[\"value\"]>125)].index\n",
    "df.drop(indexpath, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b660494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nan = df.isnull().sum()\n",
    "print ('Count of NaN: ' + str(count_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575328d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt,val_dt=train_test_split(df,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"pytorchvideo/\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytorchvideo.data import LabeledVideoDataset,Kinetics, make_clip_sampler\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip\n",
    ")\n",
    "\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c58d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_video_samples=16\n",
    "video_duration=5\n",
    "model_name='pul_x3d'\n",
    "batch_size=16\n",
    "# batch_size=32\n",
    "scheduler='cosine'\n",
    "clipmode='uniform'\n",
    "img_size=256\n",
    "augmentation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65298a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler,labeled_video_dataset\n",
    "from torchvision.transforms import ColorJitter,RandomAdjustSharpness,RandomAutocontrast,GaussianBlur\n",
    "train_transform = Compose(\n",
    "            [\n",
    "            ApplyTransformToKey(\n",
    "              key=\"video\",\n",
    "              transform=Compose(\n",
    "                  [\n",
    "                    UniformTemporalSubsample(num_video_samples),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "                    RandomShortSideScale(min_size=img_size+16, max_size=img_size+32),\n",
    "                    CenterCropVideo(img_size),\n",
    "                    Permute([1,0,2,3]),\n",
    "                    RandomAdjustSharpness(1.2),\n",
    "                    RandomAutocontrast(),\n",
    "                    Permute([1,0,2,3]),\n",
    "                    RandomHorizontalFlip(p=0.5)\n",
    "                    # GaussianBlur(kernel_size=(7, 13), sigma=(0.1, 0.2))\n",
    "\n",
    "                  ]\n",
    "                ),\n",
    "              ),\n",
    "            ]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuneable params\n",
    "# num_video_samples=24\n",
    "from time import sleep\n",
    "import torchvision.models as models\n",
    "# from scripts.cnnlstm import CNNLSTM\n",
    "class OurModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(OurModel,self).__init__()\n",
    "\n",
    "        self.scheduler=scheduler\n",
    "        self.metric=MeanAbsoluteError()\n",
    "        self.model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\n",
    "        self.model.blocks[5].proj=nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "\n",
    "        # self.model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=False)\n",
    "        # self.model.blocks[5]=nn.Sequential(*list(self.model.blocks[5].children())[:-2])\n",
    "        # self.model.blocks[5][2]=nn.Sequential(nn.AdaptiveAvgPool3d(1),\n",
    "        #                          nn.Flatten(),\n",
    "        #                          nn.Linear(2048,1024),\n",
    "        #                          nn.ReLU(),\n",
    "        #                          nn.Linear(1024,1))\n",
    "\n",
    "        self.lr=1e-3\n",
    "        self.batch_size=batch_size\n",
    "        self.numworker=2\n",
    "        self.criterion=nn.MSELoss(reduction='mean')\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt=torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
    "        if self.scheduler=='cosine':\n",
    "            scheduler=CosineAnnealingLR(opt,T_max=10,  eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='reduce':\n",
    "            scheduler=ReduceLROnPlateau(opt,mode='min', factor=0.5, patience=5)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler,'monitor':'val_loss'}\n",
    "        elif self.scheduler=='warm':\n",
    "            scheduler=CosineAnnealingWarmRestarts(opt,T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='cycle':\n",
    "            opt=torch.optim.AdamW(params=self.parameters(),lr=1e-6 )\n",
    "            scheduler=OneCycleLR(opt,max_lr=1e-2,epochs=15,steps_per_epoch=len(self.train_df)//self.batch_size//4)\n",
    "            lr_scheduler = {'scheduler': scheduler, 'interval': 'step'}\n",
    "            return {'optimizer': opt, 'lr_scheduler': lr_scheduler}\n",
    "        elif self.scheduler=='lambda':\n",
    "            lambda1 = lambda epoch: 0.9 ** epoch\n",
    "            scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda1)\n",
    "            return {'optimizer': opt, 'lr_scheduler': scheduler}\n",
    "        elif self.scheduler=='constant':\n",
    "            return opt\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset=labeled_video_dataset(train_df,\n",
    "                   clip_sampler=make_clip_sampler(clipmode, video_duration),\\\n",
    "                    transform=train_transform, decode_audio=False)\n",
    "\n",
    "        train_loader=DataLoader(train_dataset,batch_size=self.batch_size,\n",
    "                   num_workers=self.numworker,\n",
    "                   pin_memory=False)\n",
    "        return train_loader\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        out = self(batch[\"video\"])\n",
    "#         print(\"out\")\n",
    "        label=batch['label'].float()\n",
    "#         print(\"label\")\n",
    "        # label=batch['label'].int()\n",
    "        loss=self.criterion(out,label)\n",
    "#         print(\"loss\")\n",
    "        mae=self.metric(out,label)\n",
    "#         print(\"mae\")\n",
    "        # mae=self.metric(torch.exp(out),torch.exp(label))\n",
    "        return {'loss':loss,'mae':mae.detach()}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        mae=torch.stack([x[\"mae\"] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        self.log('train_loss', loss,batch_size=self.batch_size)\n",
    "        self.log('train_mae', mae,batch_size=self.batch_size)\n",
    "        print('training loss ',self.current_epoch,loss,mae)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset=labeled_video_dataset(val_df,\n",
    "                   clip_sampler=make_clip_sampler(clipmode, video_duration),\\\n",
    "                    transform=train_transform,  decode_audio=False)\n",
    "\n",
    "        val_loader=DataLoader(val_dataset,shuffle=False,\n",
    "                   batch_size=self.batch_size,\n",
    "                   num_workers=self.numworker,\n",
    "                   pin_memory=False)\n",
    "        return val_loader\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        out = self(batch[\"video\"])\n",
    "#         print(\"validation\")\n",
    "        # label=batch['label'].int()\n",
    "        label=batch['label'].float()\n",
    "#         print(\"label\")\n",
    "        loss=self.criterion(out,label)\n",
    "#         print(\"lossss\")\n",
    "        # mae=self.metric(torch.exp(out),torch.exp(label))\n",
    "        mae=self.metric(out,label)\n",
    "#         print(\"maaa\")\n",
    "        return {'loss':loss,'mae':mae.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        mae=torch.stack([x[\"mae\"] for x in outputs]).mean().cpu().numpy().round(2)\n",
    "        print('validation loss ',self.current_epoch,loss,mae)\n",
    "        self.log('val_loss', loss,batch_size=self.batch_size)\n",
    "        self.log('val_mae',mae,batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OurModel()\n",
    "seed_everything(0)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = Trainer(max_epochs=60,\n",
    "#         deterministic=True,\n",
    "        gpus=1,precision=16,\n",
    "        accumulate_grad_batches=2,\n",
    "        enable_progress_bar = True,\n",
    "        num_sanity_val_steps=0,\n",
    "        #gradient_clip_val=0.5,\n",
    "        callbacks=[lr_monitor]\n",
    "#         logger=wandb_logger\n",
    "                                    )\n",
    "trainer.fit(model)\n",
    "res=trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5048bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx='temp/'+'_'.join([model_name,scheduler,clipmode,'pulse_v3.onnx'])\n",
    "input_sample = torch.randn((1,3,16,256,256))\n",
    "model.to_onnx(onnx, input_sample,opset_version=11, export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771d215",
   "metadata": {},
   "outputs": [],
   "source": [
    " wandb_logger.experiment.config.update({\n",
    "\"num_video_samples\": num_video_samples,\n",
    "\"video_duration\":video_duration,\n",
    "\"batch_size\":batch_size,\n",
    "\"clipmode\":clipmode,\n",
    "\"scheduler\": scheduler,\n",
    "\"augmentation\":augmentation,\n",
    "\"val_mae\": res[0]['val_mae'],\n",
    "\"val_loss\": res[0]['val_loss']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6263fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment.save(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=labeled_video_dataset(val_df,\n",
    "                   clip_sampler=make_clip_sampler('random', video_duration),\\\n",
    "                    transform=train_transform,  decode_audio=False)\n",
    "\n",
    "val_loader=DataLoader(test_dataset,batch_size=1,\n",
    "           num_workers=2,\n",
    "           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165caf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,labels,abss=[],[],[]\n",
    "model.eval()\n",
    "model=model.cuda()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        pred=np.exp(model(batch['video']).cpu().detach().numpy()).astype(int)\n",
    "        label=int(np.exp(batch['label'].numpy()))\n",
    "    #     print('true:',label,'pred',pred)\n",
    "\n",
    "        abss.append(np.abs(label-pred))\n",
    "        preds.append(pred)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('abs',np.max(abss),np.median(abss),np.min(abss),np.mean(abss).round(1))\n",
    "print('label',np.max(labels),np.min(labels),np.mean(labels).round(1))\n",
    "print('preds',np.max(preds),np.min(preds),np.mean(preds).round(1))\n",
    "print('preds_diff',np.max(preds)-np.min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment.config.update({\n",
    "\"max_abs\": np.max(abss),\n",
    "\"mean_abs\":np.mean(abss),\n",
    "\"median_abs\":np.median(abss),\n",
    "\"max_pred\":np.max(preds),\n",
    "\"min_pred\":np.min(preds),\n",
    "\"dif_pred\":np.max(preds)-np.min(preds)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e662d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df=pd.DataFrame(zip(labels,preds,abss),columns=['labels','preds','diff'])\n",
    "out_df['labels']=out_df['labels'].apply(lambda x:x[0])\n",
    "out_df['preds']=out_df['preds'].apply(lambda x:x[0])\n",
    "out_df['diff']=out_df['diff'].apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.log_table(key=\"samples\", columns=list(out_df.columns), data=out_df)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca9a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da7a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee4d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d2b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0d34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79df95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03957313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8c5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1217c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208dece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
